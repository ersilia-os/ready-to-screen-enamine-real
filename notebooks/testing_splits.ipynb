{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d06baa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NAME: NaturalProducts\n",
      "IND: 015\n",
      "START: 150000001\n",
      "END: 160000001\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import pickle\n",
    "import os\n",
    "import bz2\n",
    "import sys\n",
    "\n",
    "# root = os.path.dirname(os.path.abspath(__file__))\n",
    "root = '.'\n",
    "os.chdir(root)\n",
    "sys.path.append(os.path.join(root, \"..\", \"src\"))\n",
    "from src import upload, list_files\n",
    "tmp_dir = os.path.join(root, \"..\", \"tmp\")\n",
    "data_dir = os.path.join(root, \"..\", \"data\")\n",
    "\n",
    "# Get split and load data\n",
    "# split = int(sys.argv[1])\n",
    "split = 15\n",
    "NAME, IND, START, END = pickle.load(open(os.path.join(data_dir, \"splits.pkl\"), \"rb\"))[split]\n",
    "sys.stderr.write(f\"NAME: {NAME}\\n\")\n",
    "sys.stderr.write(f\"IND: {IND}\\n\")\n",
    "sys.stderr.write(f\"START: {START}\\n\")\n",
    "sys.stderr.write(f\"END: {END}\\n\")\n",
    "sys.stderr.flush()\n",
    "\n",
    "# Mapping name to file\n",
    "name_to_file = {\"NaturalProducts\": \"Enamine_REAL_natural_products_like_cxsmiles.cxsmiles.bz2\",\n",
    "                \"Sample\": \"2025.02_Enamine_REAL_DB_1B.cxsmiles.bz2\",\n",
    "                \"LeadLike\": \"Enamine_REAL_lead-like_cxsmiles.cxsmiles.bz2\"}\n",
    "\n",
    "# Define variables\n",
    "FOLDER_ID = \"1bWrCvi5FXodxQ2S88nYLecHDjk5Jer8Y\"\n",
    "PATH_TO_SERVICE = os.path.join(data_dir, \"service.json\")\n",
    "\n",
    "# Get filenames\n",
    "FILENAME = f\"Enamine_REAL_{NAME}_{IND}.csv\"\n",
    "FILENAME_ZIP = FILENAME + \".zip\"\n",
    "\n",
    "# List files in Google Drive Folder and check that file does not exist\n",
    "files_in_drive = list_files(PATH_TO_SERVICE, FOLDER_ID)\n",
    "if FILENAME_ZIP in files_in_drive:\n",
    "    raise FileExistsError(f\"{FILENAME_ZIP} already exists in Google Drive folder {FOLDER_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cba247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file...\n",
      "Parsing done...\n",
      "Zipping...\n",
      "Uploading...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../service.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m sys.stderr.write(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUploading...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m sys.stderr.flush()\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFILENAME_ZIP\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../service.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFOLDER_ID\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/aloy/home/acomajuncosa/Ersilia/ready-to-screen-enamine-real/notebooks/../src/src.py:125\u001b[39m, in \u001b[36mupload\u001b[39m\u001b[34m(file_path, service_file, folder_id)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupload\u001b[39m(file_path, service_file, folder_id):\n\u001b[32m    100\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m    Upload a local file to a specified Google Drive folder using a service account.\u001b[39;00m\n\u001b[32m    102\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \u001b[33;03m    The HTTP timeout is extended to 600 seconds to support large file transfers.\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     creds = \u001b[43mCredentials\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_service_account_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://www.googleapis.com/auth/drive.file\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     drive_service = build(\u001b[33m\"\u001b[39m\u001b[33mdrive\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mv3\u001b[39m\u001b[33m\"\u001b[39m, credentials=creds)\n\u001b[32m    127\u001b[39m     file_metadata = {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: os.path.basename(file_path), \u001b[33m\"\u001b[39m\u001b[33mparents\u001b[39m\u001b[33m\"\u001b[39m: [folder_id]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/enamine/lib/python3.12/site-packages/google/oauth2/service_account.py:264\u001b[39m, in \u001b[36mCredentials.from_service_account_file\u001b[39m\u001b[34m(cls, filename, **kwargs)\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_service_account_file\u001b[39m(\u001b[38;5;28mcls\u001b[39m, filename, **kwargs):\n\u001b[32m    254\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Creates a Credentials instance from a service account json file.\u001b[39;00m\n\u001b[32m    255\u001b[39m \n\u001b[32m    256\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    262\u001b[39m \u001b[33;03m            credentials.\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     info, signer = \u001b[43m_service_account_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_filename\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclient_email\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtoken_uri\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._from_signer_and_info(signer, info, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/enamine/lib/python3.12/site-packages/google/auth/_service_account_info.py:78\u001b[39m, in \u001b[36mfrom_filename\u001b[39m\u001b[34m(filename, require, use_rsa_signer)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_filename\u001b[39m(filename, require=\u001b[38;5;28;01mNone\u001b[39;00m, use_rsa_signer=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     65\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Reads a Google service account JSON file and returns its parsed info.\u001b[39;00m\n\u001b[32m     66\u001b[39m \n\u001b[32m     67\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m \u001b[33;03m            info and a signer instance.\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[32m     79\u001b[39m         data = json.load(json_file)\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data, from_dict(data, require=require, use_rsa_signer=use_rsa_signer)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../service.json'"
     ]
    }
   ],
   "source": [
    "ROWS = []\n",
    "\n",
    "# Parse the original SMILES file\n",
    "data_dir = \"/aloy/scratch/acomajuncosa/Ersilia/Enamine_libs\"\n",
    "with bz2.open(os.path.join(data_dir, name_to_file[NAME]), \"rt\") as f:\n",
    "\n",
    "    # Read the header\n",
    "    header = f.readline().rstrip(\"\\n\").split(\"\\t\")\n",
    "\n",
    "    # Take 'smiles' and 'id' indexes\n",
    "    smiles_idx = header.index(\"smiles\")\n",
    "    id_idx = header.index(\"id\")\n",
    "\n",
    "    sys.stderr.write(f\"Parsing file...\\n\")\n",
    "    sys.stderr.flush()\n",
    "\n",
    "    with open(os.path.join(tmp_dir, FILENAME), \"w\") as output_file:\n",
    "\n",
    "        # Write header\n",
    "        output_file.write(\"smiles\\tid\\n\")\n",
    "\n",
    "        # Take lines between START and END\n",
    "        for line in islice(f, START, END):\n",
    "            fields = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            output_file.write(fields[smiles_idx])\n",
    "            output_file.write(\"\\t\")\n",
    "            output_file.write(fields[id_idx])\n",
    "            output_file.write(\"\\n\")\n",
    "\n",
    "    sys.stderr.write(f\"Parsing done...\\n\")\n",
    "    sys.stderr.flush()\n",
    "\n",
    "# CSV to ZIP\n",
    "sys.stderr.write(f\"Zipping...\\n\")\n",
    "sys.stderr.flush()\n",
    "with zipfile.ZipFile(os.path.join(tmp_dir, FILENAME_ZIP), \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.write(os.path.join(tmp_dir, FILENAME), arcname=FILENAME)\n",
    "\n",
    "# Upload to Google Drive\n",
    "sys.stderr.write(f\"Uploading...\\n\")\n",
    "sys.stderr.flush()\n",
    "upload(os.path.join(tmp_dir, FILENAME_ZIP), PATH_TO_SERVICE, folder_id=FOLDER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e189ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b238f83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b34f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enamine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
